name: "PVANET"

layer {
  name: "data"
  type: "UnitBoxData"
  top: "data"
  top: "labels"
  include {
    phase: TRAIN
  }
  unitbox_data_param {
    root_folder: ""
    source: "/mnt/lustre/liuxuebo/text_detect/icdar_train.txt"
    batch_size: 4
    shuffle: true
    is_color: true
    min_scale: 0.6
    max_scale: 2.0
    min_size: 640
    max_size: 2560
    min_ratio: 0.8
    max_ratio: 1.2
    label_resize: 4
    #new_height: 736
    #new_width: 1280
    crop_size: 640
    mean_value: 122
    mean_value: 122
    mean_value: 122
    mirror: true
    min_rotate: -10
    max_rotate: 10
  }
}
layer {
  name: "data"
  type: "UnitBoxData"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  unitbox_data_param {
    root_folder: ""
    source: "/mnt/lustre/liuxuebo/text_detect/icdar_test.txt"
    batch_size: 2
    shuffle: true
    is_color: true
    min_scale: 0.6
    max_scale: 2.0
    min_ratio: 0.8
    max_ratio: 1.2
    label_resize: 4
    #new_height: 736
    #new_width: 1280
    crop_size: 640
    mean_value: 122
    mean_value: 122
    mean_value: 122
    mirror: true
    min_rotate: -10
    max_rotate: 10
  }
}

layer {
  name: "slice_labels"
  type: "Slice"
  bottom: "labels"
  top: "label1"
  top: "label2"
  top: "label3"
  top: "gt_bbox"
  top: "ignore_bbox"
  slice_param {
    slice_point: 1
    slice_point: 6
    slice_point: 14
    slice_point: 15
  }
}

layer {
  name: "silence"
  type: "Silence"
  bottom: "label3"
}

################################################################################
## Convolution
################################################################################

layer {
  name: "conv1_1/conv"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1/conv"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 3
    pad_w: 3
    kernel_h: 7
    kernel_w: 7
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv1_1/bn"
  type: "BatchNorm"
  bottom: "conv1_1/conv"
  top: "conv1_1/conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1_1/neg"
  type: "Power"
  bottom: "conv1_1/conv"
  top: "conv1_1/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv1_1/concat"
  type: "Concat"
  bottom: "conv1_1/conv"
  bottom: "conv1_1/neg"
  top: "conv1_1"
}
layer {
  name: "conv1_1/scale"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1/relu"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2_1/1/conv"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/2/bn"
  type: "BatchNorm"
  bottom: "conv2_1/1"
  top: "conv2_1/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/2/bn_scale"
  type: "Scale"
  bottom: "conv2_1/2/pre"
  top: "conv2_1/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/2/relu"
  type: "ReLU"
  bottom: "conv2_1/2/pre"
  top: "conv2_1/2/pre"
}
layer {
  name: "conv2_1/2/conv"
  type: "Convolution"
  bottom: "conv2_1/2/pre"
  top: "conv2_1/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/3/bn"
  type: "BatchNorm"
  bottom: "conv2_1/2"
  top: "conv2_1/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/3/neg"
  type: "Power"
  bottom: "conv2_1/3/pre"
  top: "conv2_1/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv2_1/3/concat"
  type: "Concat"
  bottom: "conv2_1/3/pre"
  bottom: "conv2_1/3/neg"
  top: "conv2_1/3/preAct"
}
layer {
  name: "conv2_1/3/scale"
  type: "Scale"
  bottom: "conv2_1/3/preAct"
  top: "conv2_1/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/3/relu"
  type: "ReLU"
  bottom: "conv2_1/3/preAct"
  top: "conv2_1/3/preAct"
}
layer {
  name: "conv2_1/3/conv"
  type: "Convolution"
  bottom: "conv2_1/3/preAct"
  top: "conv2_1/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/proj"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1/proj"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1/3"
  bottom: "conv2_1/proj"
  top: "conv2_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv2_2/1/bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_2/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2/1/bn_scale"
  type: "Scale"
  bottom: "conv2_2/1/pre"
  top: "conv2_2/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/1/relu"
  type: "ReLU"
  bottom: "conv2_2/1/pre"
  top: "conv2_2/1/pre"
}
layer {
  name: "conv2_2/1/conv"
  type: "Convolution"
  bottom: "conv2_2/1/pre"
  top: "conv2_2/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_2/2/bn"
  type: "BatchNorm"
  bottom: "conv2_2/1"
  top: "conv2_2/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2/2/bn_scale"
  type: "Scale"
  bottom: "conv2_2/2/pre"
  top: "conv2_2/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/2/relu"
  type: "ReLU"
  bottom: "conv2_2/2/pre"
  top: "conv2_2/2/pre"
}
layer {
  name: "conv2_2/2/conv"
  type: "Convolution"
  bottom: "conv2_2/2/pre"
  top: "conv2_2/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_2/3/bn"
  type: "BatchNorm"
  bottom: "conv2_2/2"
  top: "conv2_2/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2/3/neg"
  type: "Power"
  bottom: "conv2_2/3/pre"
  top: "conv2_2/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv2_2/3/concat"
  type: "Concat"
  bottom: "conv2_2/3/pre"
  bottom: "conv2_2/3/neg"
  top: "conv2_2/3/preAct"
}
layer {
  name: "conv2_2/3/scale"
  type: "Scale"
  bottom: "conv2_2/3/preAct"
  top: "conv2_2/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/3/relu"
  type: "ReLU"
  bottom: "conv2_2/3/preAct"
  top: "conv2_2/3/preAct"
}
layer {
  name: "conv2_2/3/conv"
  type: "Convolution"
  bottom: "conv2_2/3/preAct"
  top: "conv2_2/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_2/input"
  type: "Power"
  bottom: "conv2_1"
  top: "conv2_2/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2/3"
  bottom: "conv2_2/input"
  top: "conv2_2"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv2_3/1/bn"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_3/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3/1/bn_scale"
  type: "Scale"
  bottom: "conv2_3/1/pre"
  top: "conv2_3/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3/1/relu"
  type: "ReLU"
  bottom: "conv2_3/1/pre"
  top: "conv2_3/1/pre"
}
layer {
  name: "conv2_3/1/conv"
  type: "Convolution"
  bottom: "conv2_3/1/pre"
  top: "conv2_3/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_3/2/bn"
  type: "BatchNorm"
  bottom: "conv2_3/1"
  top: "conv2_3/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3/2/bn_scale"
  type: "Scale"
  bottom: "conv2_3/2/pre"
  top: "conv2_3/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3/2/relu"
  type: "ReLU"
  bottom: "conv2_3/2/pre"
  top: "conv2_3/2/pre"
}
layer {
  name: "conv2_3/2/conv"
  type: "Convolution"
  bottom: "conv2_3/2/pre"
  top: "conv2_3/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_3/3/bn"
  type: "BatchNorm"
  bottom: "conv2_3/2"
  top: "conv2_3/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3/3/neg"
  type: "Power"
  bottom: "conv2_3/3/pre"
  top: "conv2_3/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv2_3/3/concat"
  type: "Concat"
  bottom: "conv2_3/3/pre"
  bottom: "conv2_3/3/neg"
  top: "conv2_3/3/preAct"
}
layer {
  name: "conv2_3/3/scale"
  type: "Scale"
  bottom: "conv2_3/3/preAct"
  top: "conv2_3/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3/3/relu"
  type: "ReLU"
  bottom: "conv2_3/3/preAct"
  top: "conv2_3/3/preAct"
}
layer {
  name: "conv2_3/3/conv"
  type: "Convolution"
  bottom: "conv2_3/3/preAct"
  top: "conv2_3/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_3/input"
  type: "Power"
  bottom: "conv2_2"
  top: "conv2_3/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3/3"
  bottom: "conv2_3/input"
  top: "conv2_3"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv3_1/1/bn"
  type: "BatchNorm"
  bottom: "conv2_3"
  top: "conv3_1/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/1/bn_scale"
  type: "Scale"
  bottom: "conv3_1/1/pre"
  top: "conv3_1/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/1/relu"
  type: "ReLU"
  bottom: "conv3_1/1/pre"
  top: "conv3_1/1/pre"
}
layer {
  name: "conv3_1/1/conv"
  type: "Convolution"
  bottom: "conv3_1/1/pre"
  top: "conv3_1/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv3_1/2/bn"
  type: "BatchNorm"
  bottom: "conv3_1/1"
  top: "conv3_1/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/2/bn_scale"
  type: "Scale"
  bottom: "conv3_1/2/pre"
  top: "conv3_1/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/2/relu"
  type: "ReLU"
  bottom: "conv3_1/2/pre"
  top: "conv3_1/2/pre"
}
layer {
  name: "conv3_1/2/conv"
  type: "Convolution"
  bottom: "conv3_1/2/pre"
  top: "conv3_1/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_1/3/bn"
  type: "BatchNorm"
  bottom: "conv3_1/2"
  top: "conv3_1/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/3/neg"
  type: "Power"
  bottom: "conv3_1/3/pre"
  top: "conv3_1/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv3_1/3/concat"
  type: "Concat"
  bottom: "conv3_1/3/pre"
  bottom: "conv3_1/3/neg"
  top: "conv3_1/3/preAct"
}
layer {
  name: "conv3_1/3/scale"
  type: "Scale"
  bottom: "conv3_1/3/preAct"
  top: "conv3_1/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/3/relu"
  type: "ReLU"
  bottom: "conv3_1/3/preAct"
  top: "conv3_1/3/preAct"
}
layer {
  name: "conv3_1/3/conv"
  type: "Convolution"
  bottom: "conv3_1/3/preAct"
  top: "conv3_1/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_1/proj"
  type: "Convolution"
  bottom: "conv3_1/1/pre"
  top: "conv3_1/proj"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1/3"
  bottom: "conv3_1/proj"
  top: "conv3_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv3_2/1/bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_2/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/1/bn_scale"
  type: "Scale"
  bottom: "conv3_2/1/pre"
  top: "conv3_2/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/1/relu"
  type: "ReLU"
  bottom: "conv3_2/1/pre"
  top: "conv3_2/1/pre"
}
layer {
  name: "conv3_2/1/conv"
  type: "Convolution"
  bottom: "conv3_2/1/pre"
  top: "conv3_2/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_2/2/bn"
  type: "BatchNorm"
  bottom: "conv3_2/1"
  top: "conv3_2/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/2/bn_scale"
  type: "Scale"
  bottom: "conv3_2/2/pre"
  top: "conv3_2/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/2/relu"
  type: "ReLU"
  bottom: "conv3_2/2/pre"
  top: "conv3_2/2/pre"
}
layer {
  name: "conv3_2/2/conv"
  type: "Convolution"
  bottom: "conv3_2/2/pre"
  top: "conv3_2/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_2/3/bn"
  type: "BatchNorm"
  bottom: "conv3_2/2"
  top: "conv3_2/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/3/neg"
  type: "Power"
  bottom: "conv3_2/3/pre"
  top: "conv3_2/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv3_2/3/concat"
  type: "Concat"
  bottom: "conv3_2/3/pre"
  bottom: "conv3_2/3/neg"
  top: "conv3_2/3/preAct"
}
layer {
  name: "conv3_2/3/scale"
  type: "Scale"
  bottom: "conv3_2/3/preAct"
  top: "conv3_2/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/3/relu"
  type: "ReLU"
  bottom: "conv3_2/3/preAct"
  top: "conv3_2/3/preAct"
}
layer {
  name: "conv3_2/3/conv"
  type: "Convolution"
  bottom: "conv3_2/3/preAct"
  top: "conv3_2/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_2/input"
  type: "Power"
  bottom: "conv3_1"
  top: "conv3_2/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2/3"
  bottom: "conv3_2/input"
  top: "conv3_2"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv3_3/1/bn"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_3/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3/1/bn_scale"
  type: "Scale"
  bottom: "conv3_3/1/pre"
  top: "conv3_3/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/1/relu"
  type: "ReLU"
  bottom: "conv3_3/1/pre"
  top: "conv3_3/1/pre"
}
layer {
  name: "conv3_3/1/conv"
  type: "Convolution"
  bottom: "conv3_3/1/pre"
  top: "conv3_3/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_3/2/bn"
  type: "BatchNorm"
  bottom: "conv3_3/1"
  top: "conv3_3/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3/2/bn_scale"
  type: "Scale"
  bottom: "conv3_3/2/pre"
  top: "conv3_3/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/2/relu"
  type: "ReLU"
  bottom: "conv3_3/2/pre"
  top: "conv3_3/2/pre"
}
layer {
  name: "conv3_3/2/conv"
  type: "Convolution"
  bottom: "conv3_3/2/pre"
  top: "conv3_3/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_3/3/bn"
  type: "BatchNorm"
  bottom: "conv3_3/2"
  top: "conv3_3/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3/3/neg"
  type: "Power"
  bottom: "conv3_3/3/pre"
  top: "conv3_3/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv3_3/3/concat"
  type: "Concat"
  bottom: "conv3_3/3/pre"
  bottom: "conv3_3/3/neg"
  top: "conv3_3/3/preAct"
}
layer {
  name: "conv3_3/3/scale"
  type: "Scale"
  bottom: "conv3_3/3/preAct"
  top: "conv3_3/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/3/relu"
  type: "ReLU"
  bottom: "conv3_3/3/preAct"
  top: "conv3_3/3/preAct"
}
layer {
  name: "conv3_3/3/conv"
  type: "Convolution"
  bottom: "conv3_3/3/preAct"
  top: "conv3_3/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_3/input"
  type: "Power"
  bottom: "conv3_2"
  top: "conv3_3/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3/3"
  bottom: "conv3_3/input"
  top: "conv3_3"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv3_4/1/bn"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_4/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4/1/bn_scale"
  type: "Scale"
  bottom: "conv3_4/1/pre"
  top: "conv3_4/1/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4/1/relu"
  type: "ReLU"
  bottom: "conv3_4/1/pre"
  top: "conv3_4/1/pre"
}
layer {
  name: "conv3_4/1/conv"
  type: "Convolution"
  bottom: "conv3_4/1/pre"
  top: "conv3_4/1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_4/2/bn"
  type: "BatchNorm"
  bottom: "conv3_4/1"
  top: "conv3_4/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4/2/bn_scale"
  type: "Scale"
  bottom: "conv3_4/2/pre"
  top: "conv3_4/2/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4/2/relu"
  type: "ReLU"
  bottom: "conv3_4/2/pre"
  top: "conv3_4/2/pre"
}
layer {
  name: "conv3_4/2/conv"
  type: "Convolution"
  bottom: "conv3_4/2/pre"
  top: "conv3_4/2"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_4/3/bn"
  type: "BatchNorm"
  bottom: "conv3_4/2"
  top: "conv3_4/3/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4/3/neg"
  type: "Power"
  bottom: "conv3_4/3/pre"
  top: "conv3_4/3/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 0
  }
}
layer {
  name: "conv3_4/3/concat"
  type: "Concat"
  bottom: "conv3_4/3/pre"
  bottom: "conv3_4/3/neg"
  top: "conv3_4/3/preAct"
}
layer {
  name: "conv3_4/3/scale"
  type: "Scale"
  bottom: "conv3_4/3/preAct"
  top: "conv3_4/3/preAct"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4/3/relu"
  type: "ReLU"
  bottom: "conv3_4/3/preAct"
  top: "conv3_4/3/preAct"
}
layer {
  name: "conv3_4/3/conv"
  type: "Convolution"
  bottom: "conv3_4/3/preAct"
  top: "conv3_4/3"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_4/input"
  type: "Power"
  bottom: "conv3_3"
  top: "conv3_4/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv3_4"
  type: "Eltwise"
  bottom: "conv3_4/3"
  bottom: "conv3_4/input"
  top: "conv3_4"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv4_1/incep/bn"
  type: "BatchNorm"
  bottom: "conv3_4"
  top: "conv4_1/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/pre"
  top: "conv4_1/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/pre"
  top: "conv4_1/incep/pre"
}
layer {
  name: "conv4_1/incep/0/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/pre"
  top: "conv4_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/0"
  top: "conv4_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/0"
  top: "conv4_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/0/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/0"
  top: "conv4_1/incep/0"
}
layer {
  name: "conv4_1/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/pre"
  top: "conv4_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_reduce"
}
layer {
  name: "conv4_1/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/1_0"
  top: "conv4_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/1_0"
  top: "conv4_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/1_0"
  top: "conv4_1/incep/1_0"
}
layer {
  name: "conv4_1/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/pre"
  top: "conv4_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_reduce"
}
layer {
  name: "conv4_1/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_0"
}
layer {
  name: "conv4_1/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/2_1"
  top: "conv4_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/2_1"
  top: "conv4_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/2_1"
  top: "conv4_1/incep/2_1"
}
layer {
  name: "conv4_1/incep/pool"
  type: "Pooling"
  bottom: "conv4_1/incep/pre"
  top: "conv4_1/incep/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4_1/incep/poolproj/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/pool"
  top: "conv4_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/poolproj/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/poolproj/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/poolproj/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep/poolproj"
}
layer {
  name: "conv4_1/incep"
  type: "Concat"
  bottom: "conv4_1/incep/0"
  bottom: "conv4_1/incep/1_0"
  bottom: "conv4_1/incep/2_1"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep"
}
layer {
  name: "conv4_1/out/conv"
  type: "Convolution"
  bottom: "conv4_1/incep"
  top: "conv4_1/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/proj"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1/proj"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv4_1/out"
  bottom: "conv4_1/proj"
  top: "conv4_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv4_2/incep/bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_2/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/pre"
  top: "conv4_2/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/pre"
  top: "conv4_2/incep/pre"
}
layer {
  name: "conv4_2/incep/0/conv"
  type: "Convolution"
  bottom: "conv4_2/incep/pre"
  top: "conv4_2/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv4_2/incep/0"
  top: "conv4_2/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/0"
  top: "conv4_2/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/0/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/0"
  top: "conv4_2/incep/0"
}
layer {
  name: "conv4_2/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv4_2/incep/pre"
  top: "conv4_2/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_2/incep/1_reduce"
  top: "conv4_2/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/1_reduce"
  top: "conv4_2/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/1_reduce"
  top: "conv4_2/incep/1_reduce"
}
layer {
  name: "conv4_2/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv4_2/incep/1_reduce"
  top: "conv4_2/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv4_2/incep/1_0"
  top: "conv4_2/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/1_0"
  top: "conv4_2/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/1_0"
  top: "conv4_2/incep/1_0"
}
layer {
  name: "conv4_2/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv4_2/incep/pre"
  top: "conv4_2/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_2/incep/2_reduce"
  top: "conv4_2/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/2_reduce"
  top: "conv4_2/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/2_reduce"
  top: "conv4_2/incep/2_reduce"
}
layer {
  name: "conv4_2/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv4_2/incep/2_reduce"
  top: "conv4_2/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv4_2/incep/2_0"
  top: "conv4_2/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/2_0"
  top: "conv4_2/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/2_0"
  top: "conv4_2/incep/2_0"
}
layer {
  name: "conv4_2/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv4_2/incep/2_0"
  top: "conv4_2/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv4_2/incep/2_1"
  top: "conv4_2/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv4_2/incep/2_1"
  top: "conv4_2/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv4_2/incep/2_1"
  top: "conv4_2/incep/2_1"
}
layer {
  name: "conv4_2/incep"
  type: "Concat"
  bottom: "conv4_2/incep/0"
  bottom: "conv4_2/incep/1_0"
  bottom: "conv4_2/incep/2_1"
  top: "conv4_2/incep"
}
layer {
  name: "conv4_2/out/conv"
  type: "Convolution"
  bottom: "conv4_2/incep"
  top: "conv4_2/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_2/input"
  type: "Power"
  bottom: "conv4_1"
  top: "conv4_2/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv4_2"
  type: "Eltwise"
  bottom: "conv4_2/out"
  bottom: "conv4_2/input"
  top: "conv4_2"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv4_3/incep/bn"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_3/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/pre"
  top: "conv4_3/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/pre"
  top: "conv4_3/incep/pre"
}
layer {
  name: "conv4_3/incep/0/conv"
  type: "Convolution"
  bottom: "conv4_3/incep/pre"
  top: "conv4_3/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv4_3/incep/0"
  top: "conv4_3/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/0"
  top: "conv4_3/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/0/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/0"
  top: "conv4_3/incep/0"
}
layer {
  name: "conv4_3/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv4_3/incep/pre"
  top: "conv4_3/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_3/incep/1_reduce"
  top: "conv4_3/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/1_reduce"
  top: "conv4_3/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/1_reduce"
  top: "conv4_3/incep/1_reduce"
}
layer {
  name: "conv4_3/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv4_3/incep/1_reduce"
  top: "conv4_3/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv4_3/incep/1_0"
  top: "conv4_3/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/1_0"
  top: "conv4_3/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/1_0"
  top: "conv4_3/incep/1_0"
}
layer {
  name: "conv4_3/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv4_3/incep/pre"
  top: "conv4_3/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_3/incep/2_reduce"
  top: "conv4_3/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/2_reduce"
  top: "conv4_3/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/2_reduce"
  top: "conv4_3/incep/2_reduce"
}
layer {
  name: "conv4_3/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv4_3/incep/2_reduce"
  top: "conv4_3/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv4_3/incep/2_0"
  top: "conv4_3/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/2_0"
  top: "conv4_3/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/2_0"
  top: "conv4_3/incep/2_0"
}
layer {
  name: "conv4_3/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv4_3/incep/2_0"
  top: "conv4_3/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv4_3/incep/2_1"
  top: "conv4_3/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv4_3/incep/2_1"
  top: "conv4_3/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv4_3/incep/2_1"
  top: "conv4_3/incep/2_1"
}
layer {
  name: "conv4_3/incep"
  type: "Concat"
  bottom: "conv4_3/incep/0"
  bottom: "conv4_3/incep/1_0"
  bottom: "conv4_3/incep/2_1"
  top: "conv4_3/incep"
}
layer {
  name: "conv4_3/out/conv"
  type: "Convolution"
  bottom: "conv4_3/incep"
  top: "conv4_3/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3/input"
  type: "Power"
  bottom: "conv4_2"
  top: "conv4_3/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv4_3"
  type: "Eltwise"
  bottom: "conv4_3/out"
  bottom: "conv4_3/input"
  top: "conv4_3"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv4_4/incep/bn"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_4/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/pre"
  top: "conv4_4/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/pre"
  top: "conv4_4/incep/pre"
}
layer {
  name: "conv4_4/incep/0/conv"
  type: "Convolution"
  bottom: "conv4_4/incep/pre"
  top: "conv4_4/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv4_4/incep/0"
  top: "conv4_4/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/0"
  top: "conv4_4/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/0/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/0"
  top: "conv4_4/incep/0"
}
layer {
  name: "conv4_4/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv4_4/incep/pre"
  top: "conv4_4/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_4/incep/1_reduce"
  top: "conv4_4/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/1_reduce"
  top: "conv4_4/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/1_reduce"
  top: "conv4_4/incep/1_reduce"
}
layer {
  name: "conv4_4/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv4_4/incep/1_reduce"
  top: "conv4_4/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv4_4/incep/1_0"
  top: "conv4_4/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/1_0"
  top: "conv4_4/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/1_0"
  top: "conv4_4/incep/1_0"
}
layer {
  name: "conv4_4/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv4_4/incep/pre"
  top: "conv4_4/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_4/incep/2_reduce"
  top: "conv4_4/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/2_reduce"
  top: "conv4_4/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/2_reduce"
  top: "conv4_4/incep/2_reduce"
}
layer {
  name: "conv4_4/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv4_4/incep/2_reduce"
  top: "conv4_4/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv4_4/incep/2_0"
  top: "conv4_4/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/2_0"
  top: "conv4_4/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/2_0"
  top: "conv4_4/incep/2_0"
}
layer {
  name: "conv4_4/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv4_4/incep/2_0"
  top: "conv4_4/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv4_4/incep/2_1"
  top: "conv4_4/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv4_4/incep/2_1"
  top: "conv4_4/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv4_4/incep/2_1"
  top: "conv4_4/incep/2_1"
}
layer {
  name: "conv4_4/incep"
  type: "Concat"
  bottom: "conv4_4/incep/0"
  bottom: "conv4_4/incep/1_0"
  bottom: "conv4_4/incep/2_1"
  top: "conv4_4/incep"
}
layer {
  name: "conv4_4/out/conv"
  type: "Convolution"
  bottom: "conv4_4/incep"
  top: "conv4_4/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_4/input"
  type: "Power"
  bottom: "conv4_3"
  top: "conv4_4/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv4_4"
  type: "Eltwise"
  bottom: "conv4_4/out"
  bottom: "conv4_4/input"
  top: "conv4_4"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv5_1/incep/bn"
  type: "BatchNorm"
  bottom: "conv4_4"
  top: "conv5_1/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/pre"
  top: "conv5_1/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/pre"
  top: "conv5_1/incep/pre"
}
layer {
  name: "conv5_1/incep/0/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/pre"
  top: "conv5_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv5_1/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/0"
  top: "conv5_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/0"
  top: "conv5_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/0/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/0"
  top: "conv5_1/incep/0"
}
layer {
  name: "conv5_1/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/pre"
  top: "conv5_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 96
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv5_1/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/1_reduce"
  top: "conv5_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/1_reduce"
  top: "conv5_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/1_reduce"
  top: "conv5_1/incep/1_reduce"
}
layer {
  name: "conv5_1/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/1_reduce"
  top: "conv5_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_1/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/1_0"
  top: "conv5_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/1_0"
  top: "conv5_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/1_0"
  top: "conv5_1/incep/1_0"
}
layer {
  name: "conv5_1/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/pre"
  top: "conv5_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv5_1/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/2_reduce"
  top: "conv5_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/2_reduce"
  top: "conv5_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/2_reduce"
  top: "conv5_1/incep/2_reduce"
}
layer {
  name: "conv5_1/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/2_reduce"
  top: "conv5_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_1/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/2_0"
  top: "conv5_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/2_0"
  top: "conv5_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/2_0"
  top: "conv5_1/incep/2_0"
}
layer {
  name: "conv5_1/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/2_0"
  top: "conv5_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_1/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/2_1"
  top: "conv5_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/2_1"
  top: "conv5_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/2_1"
  top: "conv5_1/incep/2_1"
}
layer {
  name: "conv5_1/incep/pool"
  type: "Pooling"
  bottom: "conv5_1/incep/pre"
  top: "conv5_1/incep/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv5_1/incep/poolproj/conv"
  type: "Convolution"
  bottom: "conv5_1/incep/pool"
  top: "conv5_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_1/incep/poolproj/bn"
  type: "BatchNorm"
  bottom: "conv5_1/incep/poolproj"
  top: "conv5_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/incep/poolproj/bn_scale"
  type: "Scale"
  bottom: "conv5_1/incep/poolproj"
  top: "conv5_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/incep/poolproj/relu"
  type: "ReLU"
  bottom: "conv5_1/incep/poolproj"
  top: "conv5_1/incep/poolproj"
}
layer {
  name: "conv5_1/incep"
  type: "Concat"
  bottom: "conv5_1/incep/0"
  bottom: "conv5_1/incep/1_0"
  bottom: "conv5_1/incep/2_1"
  bottom: "conv5_1/incep/poolproj"
  top: "conv5_1/incep"
}
layer {
  name: "conv5_1/out/conv"
  type: "Convolution"
  bottom: "conv5_1/incep"
  top: "conv5_1/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 384
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_1/proj"
  type: "Convolution"
  bottom: "conv4_4"
  top: "conv5_1/proj"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 384
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv5_1"
  type: "Eltwise"
  bottom: "conv5_1/out"
  bottom: "conv5_1/proj"
  top: "conv5_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv5_2/incep/bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_2/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/pre"
  top: "conv5_2/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/pre"
  top: "conv5_2/incep/pre"
}
layer {
  name: "conv5_2/incep/0/conv"
  type: "Convolution"
  bottom: "conv5_2/incep/pre"
  top: "conv5_2/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv5_2/incep/0"
  top: "conv5_2/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/0"
  top: "conv5_2/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/0/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/0"
  top: "conv5_2/incep/0"
}
layer {
  name: "conv5_2/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv5_2/incep/pre"
  top: "conv5_2/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 96
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_2/incep/1_reduce"
  top: "conv5_2/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/1_reduce"
  top: "conv5_2/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/1_reduce"
  top: "conv5_2/incep/1_reduce"
}
layer {
  name: "conv5_2/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv5_2/incep/1_reduce"
  top: "conv5_2/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv5_2/incep/1_0"
  top: "conv5_2/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/1_0"
  top: "conv5_2/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/1_0"
  top: "conv5_2/incep/1_0"
}
layer {
  name: "conv5_2/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv5_2/incep/pre"
  top: "conv5_2/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_2/incep/2_reduce"
  top: "conv5_2/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/2_reduce"
  top: "conv5_2/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/2_reduce"
  top: "conv5_2/incep/2_reduce"
}
layer {
  name: "conv5_2/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv5_2/incep/2_reduce"
  top: "conv5_2/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv5_2/incep/2_0"
  top: "conv5_2/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/2_0"
  top: "conv5_2/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/2_0"
  top: "conv5_2/incep/2_0"
}
layer {
  name: "conv5_2/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv5_2/incep/2_0"
  top: "conv5_2/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv5_2/incep/2_1"
  top: "conv5_2/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv5_2/incep/2_1"
  top: "conv5_2/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv5_2/incep/2_1"
  top: "conv5_2/incep/2_1"
}
layer {
  name: "conv5_2/incep"
  type: "Concat"
  bottom: "conv5_2/incep/0"
  bottom: "conv5_2/incep/1_0"
  bottom: "conv5_2/incep/2_1"
  top: "conv5_2/incep"
}
layer {
  name: "conv5_2/out/conv"
  type: "Convolution"
  bottom: "conv5_2/incep"
  top: "conv5_2/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 384
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_2/input"
  type: "Power"
  bottom: "conv5_1"
  top: "conv5_2/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv5_2"
  type: "Eltwise"
  bottom: "conv5_2/out"
  bottom: "conv5_2/input"
  top: "conv5_2"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv5_3/incep/bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_3/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/pre"
  top: "conv5_3/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/pre"
  top: "conv5_3/incep/pre"
}
layer {
  name: "conv5_3/incep/0/conv"
  type: "Convolution"
  bottom: "conv5_3/incep/pre"
  top: "conv5_3/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv5_3/incep/0"
  top: "conv5_3/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/0"
  top: "conv5_3/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/0/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/0"
  top: "conv5_3/incep/0"
}
layer {
  name: "conv5_3/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv5_3/incep/pre"
  top: "conv5_3/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 96
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_3/incep/1_reduce"
  top: "conv5_3/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/1_reduce"
  top: "conv5_3/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/1_reduce"
  top: "conv5_3/incep/1_reduce"
}
layer {
  name: "conv5_3/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv5_3/incep/1_reduce"
  top: "conv5_3/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv5_3/incep/1_0"
  top: "conv5_3/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/1_0"
  top: "conv5_3/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/1_0"
  top: "conv5_3/incep/1_0"
}
layer {
  name: "conv5_3/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv5_3/incep/pre"
  top: "conv5_3/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_3/incep/2_reduce"
  top: "conv5_3/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/2_reduce"
  top: "conv5_3/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/2_reduce"
  top: "conv5_3/incep/2_reduce"
}
layer {
  name: "conv5_3/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv5_3/incep/2_reduce"
  top: "conv5_3/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv5_3/incep/2_0"
  top: "conv5_3/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/2_0"
  top: "conv5_3/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/2_0"
  top: "conv5_3/incep/2_0"
}
layer {
  name: "conv5_3/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv5_3/incep/2_0"
  top: "conv5_3/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv5_3/incep/2_1"
  top: "conv5_3/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv5_3/incep/2_1"
  top: "conv5_3/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv5_3/incep/2_1"
  top: "conv5_3/incep/2_1"
}
layer {
  name: "conv5_3/incep"
  type: "Concat"
  bottom: "conv5_3/incep/0"
  bottom: "conv5_3/incep/1_0"
  bottom: "conv5_3/incep/2_1"
  top: "conv5_3/incep"
}
layer {
  name: "conv5_3/out/conv"
  type: "Convolution"
  bottom: "conv5_3/incep"
  top: "conv5_3/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  param {
    lr_mult: 0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 384
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_3/input"
  type: "Power"
  bottom: "conv5_2"
  top: "conv5_3/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv5_3"
  type: "Eltwise"
  bottom: "conv5_3/out"
  bottom: "conv5_3/input"
  top: "conv5_3"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv5_4/incep/bn"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_4/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/pre"
  top: "conv5_4/incep/pre"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/pre"
  top: "conv5_4/incep/pre"
}
layer {
  name: "conv5_4/incep/0/conv"
  type: "Convolution"
  bottom: "conv5_4/incep/pre"
  top: "conv5_4/incep/0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv5_4/incep/0"
  top: "conv5_4/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/0"
  top: "conv5_4/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/0/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/0"
  top: "conv5_4/incep/0"
}
layer {
  name: "conv5_4/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv5_4/incep/pre"
  top: "conv5_4/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 96
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_4/incep/1_reduce"
  top: "conv5_4/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/1_reduce"
  top: "conv5_4/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/1_reduce"
  top: "conv5_4/incep/1_reduce"
}
layer {
  name: "conv5_4/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv5_4/incep/1_reduce"
  top: "conv5_4/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv5_4/incep/1_0"
  top: "conv5_4/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/1_0"
  top: "conv5_4/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/1_0"
  top: "conv5_4/incep/1_0"
}
layer {
  name: "conv5_4/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv5_4/incep/pre"
  top: "conv5_4/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_4/incep/2_reduce"
  top: "conv5_4/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/2_reduce"
  top: "conv5_4/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/2_reduce"
  top: "conv5_4/incep/2_reduce"
}
layer {
  name: "conv5_4/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv5_4/incep/2_reduce"
  top: "conv5_4/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv5_4/incep/2_0"
  top: "conv5_4/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/2_0"
  top: "conv5_4/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/2_0"
  top: "conv5_4/incep/2_0"
}
layer {
  name: "conv5_4/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv5_4/incep/2_0"
  top: "conv5_4/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv5_4/incep/2_1"
  top: "conv5_4/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv5_4/incep/2_1"
  top: "conv5_4/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv5_4/incep/2_1"
  top: "conv5_4/incep/2_1"
}
layer {
  name: "conv5_4/incep"
  type: "Concat"
  bottom: "conv5_4/incep/0"
  bottom: "conv5_4/incep/1_0"
  bottom: "conv5_4/incep/2_1"
  top: "conv5_4/incep"
}
layer {
  name: "conv5_4/out/conv"
  type: "Convolution"
  bottom: "conv5_4/incep"
  top: "conv5_4/out"
  param {
    lr_mult: 0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv5_4/out/bn"
  type: "BatchNorm"
  bottom: "conv5_4/out"
  top: "conv5_4/out"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/out/bn_scale"
  type: "Scale"
  bottom: "conv5_4/out"
  top: "conv5_4/out"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/input"
  type: "Power"
  bottom: "conv5_3"
  top: "conv5_4/input"
  power_param {
    power: 1
    scale: 1
    shift: 0
  }
}
layer {
  name: "conv5_4"
  type: "Eltwise"
  bottom: "conv5_4/out"
  bottom: "conv5_4/input"
  top: "conv5_4"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv5_4/last_bn"
  type: "BatchNorm"
  bottom: "conv5_4"
  top: "conv5_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_4/last_bn_scale"
  type: "Scale"
  bottom: "conv5_4"
  top: "conv5_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_4/last_relu"
  type: "ReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}


##############################################################33

layer {
    name: "upsample_conv4"
    type: "Deconvolution"
    bottom: "conv5_4"
    top: "upsample_conv4"
    param { lr_mult: 0 decay_mult: 0}
    convolution_param {
        num_output: 384
        kernel_size: 4
        pad: 1
        stride: 2
        group: 384
        weight_filler: {type: "bilinear" }
        bias_term: false
    }
}


layer {
  name: "conv_conv4"
  type: "Convolution"
  bottom: "conv4_4"
  top: "conv_conv4"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_conv4_relu"
  type: "ReLU"
  bottom: "conv_conv4"
  top: "conv_conv4"
}

layer {
  name: "concat_8x"
  bottom: "upsample_conv4"
  bottom: "conv_conv4"
  top: "concat_8x"
  type: "Concat"
  concat_param { axis: 1 }
}


layer {
  name: "conv_8s_1x1"
  type: "Convolution"
  bottom: "concat_8x"
  top: "conv_8s_1x1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_8s_1x1_relu"
  type: "ReLU"
  bottom: "conv_8s_1x1"
  top: "conv_8s_1x1"
}

layer {
  name: "conv_8s_3x3"
  type: "Convolution"
  bottom: "conv_8s_1x1"
  top: "conv_8s_3x3"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_8s_3x3_relu"
  type: "ReLU"
  bottom: "conv_8s_3x3"
  top: "conv_8s_3x3"
}

###########################################################################

layer {
    name: "upsample_conv3"
    type: "Deconvolution"
    bottom: "conv_8s_3x3"
    top: "upsample_conv3"
    param { lr_mult: 0 decay_mult: 0}
    convolution_param {
        num_output: 128
        kernel_size: 4
        pad: 1
        stride: 2
        group: 128
        weight_filler: {type: "bilinear" }
        bias_term: false
    }
}


layer {
  name: "conv_conv3"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv_conv3"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_conv3_relu"
  type: "ReLU"
  bottom: "conv_conv3"
  top: "conv_conv3"
}

layer {
  name: "concat_4x"
  bottom: "upsample_conv3"
  bottom: "conv_conv3"
  top: "concat_4x"
  type: "Concat"
  concat_param { axis: 1 }
}


layer {
  name: "conv_4s_1x1"
  type: "Convolution"
  bottom: "concat_4x"
  top: "conv_4s_1x1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_4s_1x1_relu"
  type: "ReLU"
  bottom: "conv_4s_1x1"
  top: "conv_4s_1x1"
}


layer {
  name: "conv_4s_3x3"
  type: "Convolution"
  bottom: "conv_4s_1x1"
  top: "conv_4s_3x3"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_4s_3x3_relu"
  type: "ReLU"
  bottom: "conv_4s_3x3"
  top: "conv_4s_3x3"
}
###########################################################################

layer {
    name: "upsample_conv2"
    type: "Deconvolution"
    bottom: "conv_4s_3x3"
    top: "upsample_conv2"
    param { lr_mult: 0 decay_mult: 0}
    convolution_param {
        num_output: 64
        kernel_size: 4
        pad: 1
        stride: 2
        group: 64
        weight_filler: {type: "bilinear" }
        bias_term: false
    }
}


layer {
  name: "conv_conv2"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv_conv2"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_conv2_relu"
  type: "ReLU"
  bottom: "conv_conv2"
  top: "conv_conv2"
}

layer {
  name: "concat_2x"
  bottom: "upsample_conv2"
  bottom: "conv_conv2"
  top: "concat_2x"
  type: "Concat"
  concat_param { axis: 1 }
}


layer {
  name: "conv_2s_1x1"
  type: "Convolution"
  bottom: "concat_2x"
  top: "conv_2s_1x1"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_2s_1x1_relu"
  type: "ReLU"
  bottom: "conv_2s_1x1"
  top: "conv_2s_1x1"
}


layer {
  name: "conv_2s_3x3"
  type: "Convolution"
  bottom: "conv_2s_1x1"
  top: "conv_2s_3x3"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_2s_3x3_relu"
  type: "ReLU"
  bottom: "conv_2s_3x3"
  top: "conv_2s_3x3"
}

layer {
  name: "drop1"
  type: "Dropout"
  bottom: "conv_2s_3x3"
  top: "conv_2s_3x3"
  dropout_param {
    dropout_ratio: 0
  }
}
########################################
layer {
  name: "conv_final"
  type: "Convolution"
  bottom: "conv_2s_3x3"
  top: "conv_final"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_final_relu"
  type: "ReLU"
  bottom: "conv_final"
  top: "conv_final"
}

layer {
  name: "drop2"
  type: "Dropout"
  bottom: "conv_final"
  top: "conv_final"
  dropout_param {
    dropout_ratio: 0
  }
}


#####################################


layer {
    name: 'score_4s'
    type: "Convolution"
    bottom: 'conv_final'
    top: 'score_4s'
    param {
        lr_mult: 0
        decay_mult: 1
    }
    param {
        lr_mult: 0
        decay_mult: 0
   }
   convolution_param {
    num_output: 2
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
    name: "softmax"
    type: "Softmax"
    bottom: "score_4s"
    top:"score_4s_softmax"
}

layer {
    name: "ohem"
    type: "OHEM"
    bottom: "score_4s_softmax"
    bottom: "label1"
    top: "new_label1"
    ohem_param {
      min_hard_random_ratio: 0.2
      max_hard_random_ratio: 0.7
      neg_num: 1024
      min_pos_hard_random_ratio: 0.2
      max_pos_hard_random_ratio: 0.7
      pos_num: 256
      max_iteration: 50000
    }
}

layer {
    name: "loss_4s"
    type: "SoftmaxWithLoss"
    bottom: "score_4s"
    bottom: "new_label1"
    loss_param {
      ignore_label: 255
      normalize: true
    }
    top:"loss_4s"
    loss_weight: 0
    propagate_down: true
    propagate_down: false
}


##################################################################




#################################


layer {
  name: "conv_feature_prior"
  type: "Convolution"
  bottom: "conv_final"
  top: "conv_feature_prior"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_feature_prior_relu"
  type: "ReLU"
  bottom: "conv_feature_prior"
  top: "conv_feature_prior"
}


layer {
  name: "conv_maps"
  type: "Convolution"
  bottom: "conv_feature_prior"
  top: "conv_maps"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
  name: "conv_maps/relu"
  type: "ReLU"
  bottom: "conv_maps"
  top: "conv_maps"
}

layer {
  name: "conv_orient"
  type: "Convolution"
  bottom: "conv_feature_prior"
  top: "conv_orient"
  param {
    lr_mult: 0
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
  name: "concat_bbox_orient"
  type: "Concat"
  bottom: "conv_maps"
  bottom: "conv_orient"
  top: "pre_bbox_orient"
}

layer {
  name: "trans_label1"
  type: "Transpose"
  bottom: "label1"
  top: "trans_label1"
  transpose_param {
    dim: 0
    dim: 2
    dim: 3
    dim: 1
  }
}

layer {
  name: "trans_label2"
  type: "Transpose"
  bottom: "label2"
  top: "trans_label2"
  transpose_param {
    dim: 0
    dim: 2
    dim: 3
    dim: 1
  }
}

layer {
  name: "trans_pre_bbox"
  type: "Transpose"
  bottom: "pre_bbox_orient"
  top: "trans_pre_bbox_orient"
  transpose_param {
    dim: 0
    dim: 2
    dim: 3
    dim: 1
  }
}


layer {
  name: "reg_loss_forward"
  type: "IouLoss"
  bottom: "trans_pre_bbox_orient"
  bottom: "trans_label2"
  bottom: "trans_label1"
  top: "reg_loss_forward"
  iou_loss_param: {
    lambda: 10
    only_forward: true
  }
  loss_weight: 0
  propagate_down: false
  propagate_down: false
  propagate_down: false
}

layer {
  name: "trans_reg_loss_forward"
  type: "Transpose"
  bottom: "reg_loss_forward"
  top: "trans_reg_loss_forward"
  transpose_param {
    dim: 0
    dim: 3
    dim: 1
    dim: 2
  }
}

layer {
    name: "ohem_reg"
    type: "OHEM"
    bottom: "trans_reg_loss_forward"
    bottom: "label1"
    top: "new_reg_label1"
    ohem_param {
      min_pos_hard_random_ratio: 0.2
      max_pos_hard_random_ratio: 0.7
      pos_num: 256
      max_iteration: 50000
      reg: true
    }
}

layer {
  name: "trans_reg_label1"
  type: "Transpose"
  bottom: "new_reg_label1"
  top: "trans_reg_label1"
  transpose_param {
    dim: 0
    dim: 2
    dim: 3
    dim: 1
  }
}

layer {
  name: "reg_loss"
  type: "IouLoss"
  bottom: "trans_pre_bbox_orient"
  bottom: "trans_label2"
  bottom: "trans_reg_label1"
  top: "reg_loss"
  iou_loss_param: {
    lambda: 10
  }
  loss_weight: 0
  propagate_down: true
  propagate_down: false
  propagate_down: false
}

layer {
  name: 'proposal'
  type: 'Python'
  bottom: 'score_4s_softmax'
  bottom: 'pre_bbox_orient'
  bottom: 'gt_bbox'
  bottom: 'ignore_bbox'
  top: 'proposal'
  top: 'proposal_label'
  top: 'affine_param'
  top: 'proposal_w'
  python_param {
    module: 'layers.proposal'
    layer: 'ProposalLayer'
    param_str: "'phase': 1 \n'threshold': 0.1 \n'bbox_scale': 10 \n'num_proposal': 32 \n'fg_iou': 0.7 \n'bg_iou': 0.3 \n'ignore_iou': 0.3 \n'out_height': 8 \n'max_w': 128 \n'nms_score': 0.7"
  }
}
layer {
  name: "affine_transform"
  type: "AffineTransformer"
  bottom: "conv_final"
  bottom: "affine_param"
  bottom: "proposal_w"
  top: "affine_transform_feature"
  top: "cont"
  at_param {
    output_h: 8
    # output_w: 128
    cont {
      scale: 4
      shift: 0
    }
  }
}

# layer {
#   name: 'draw'
#   type: 'Python'
#   bottom: 'affine_transform_feature'
#   bottom: "proposal_label"
#   python_param {
#     module: 'layers.draw_affine_transform'
#     layer: 'DrawAffineLayer'
#     param_str: "'save_dir': /data1/liuxuebo/data/mask \n'prefix': ld"
#   }
# }


layer {
  name: "conv_at1"
  type: "Convolution"
  bottom: "affine_transform_feature"
  top: "conv_at1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_h: 2
    kernel_w: 3
    pad_h: 0
    pad_w: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_at1_relu"
  type: "ReLU"
  bottom: "conv_at1"
  top: "conv_at1"
}

layer {
  name: "pool_at1"
  type: "Pooling"
  bottom: "conv_at1"
  top: "pool_at1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}

layer {
  name: "conv_at2"
  type: "Convolution"
  bottom: "pool_at1"
  top: "conv_at2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_h: 2
    kernel_w: 3
    pad_h: 0
    pad_w: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_at2_relu"
  type: "ReLU"
  bottom: "conv_at2"
  top: "conv_at2"
}
layer {
  name: "pool_at2"
  type: "Pooling"
  bottom: "conv_at2"
  top: "pool_at2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}

layer {
  name: "conv_at3"
  type: "Convolution"
  bottom: "pool_at2"
  top: "conv_at3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_h: 2
    kernel_w: 3
    pad_h: 0
    pad_w: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv_at3_relu"
  type: "ReLU"
  bottom: "conv_at3"
  top: "conv_at3"
}

layer {
  name: "pool_at3"
  type: "Pooling"
  bottom: "conv_at3"
  top: "pool_at3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
    pad_h: 0
    pad_w: 0
  }
}

layer {
  name: "affine_transform_feature_transpose"
  bottom: "pool_at3"
  top: "affine_transform_feature_transpose"
  type: "Transpose"
  transpose_param {
    dim: 3
    dim: 0
    dim: 1
    dim: 2
  }
}

layer {
  name: "lstm_input"
  type: "Reshape"
  bottom: "affine_transform_feature_transpose"
  top: "lstm_input"
  reshape_param {
    shape { dim: -1 }
    axis: 2
    num_axes: 2
  }
}
layer {
  name: "lstm"
  type: "SLLSTM"
  bottom: "lstm_input"
  bottom: "cont"
  top: "lstm"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  recurrent_param {
    clipping_threshold: 1
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}

layer {
  name: "rlstm_input"
  type: "Reverse"
  bottom: "lstm_input"
  top: "rlstm_input"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "rlstm"
  type: "SLLSTM"
  bottom: "rlstm_input"
  bottom: "cont"
  top: "rlstm"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  recurrent_param {
    clipping_threshold: 1
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "rlstm_output"
  type: "Reverse"
  bottom: "rlstm"
  top: "rlstm_output"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "lstm_concat"
  type: "Concat"
  bottom: "lstm"
  bottom: "rlstm_output"
  top: "lstm_concat"
  concat_param {
    axis: 2
  }
}

layer {
  name: "lstm_output_reshape"
  type: "Reshape"
  bottom: "lstm_concat"
  top: "lstm_output_reshape"
  reshape_param {
    shape { dim: -1 dim: 1 }
    axis: 1
    num_axes: 1
  }
}

layer {
  name: "lstm_output"
  type: "Transpose"
  bottom: "lstm_output_reshape"
  top: "lstm_output"
  transpose_param {
    dim: 1
    dim: 3
    dim: 2
    dim: 0
  }
}


layer {
  name: 'w_pooling'
  type: 'Python'
  bottom: 'lstm_output'
  bottom: "cont"
  top: "pooling_feature"
  python_param {
    module: 'layers.w_pooling'
    layer: 'WPoolingLayer'
    param_str: "'pooling_method': ave"
  }
}
layer {
  name: "drop_fc"
  type: "Dropout"
  bottom: "pooling_feature"
  top: "pooling_feature"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc"
  type: "Convolution"
  bottom: "pooling_feature"
  top: "fc"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}

layer {
   name: "proposal_label_reshape"
   bottom: "proposal_label"
   top: "proposal_label_reshape"
   type: "Reshape"
   reshape_param { shape { dim: -1 dim: 1} }
}


layer {
    name: "loss_at"
    type: "SoftmaxWithLoss"
    bottom: "fc"
    bottom: "proposal_label_reshape"
    loss_param {
      ignore_label: 255
      normalize: true
    }
    top:"loss_at"
    loss_weight: 1
    propagate_down: true
    propagate_down: false
}

layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc"
  bottom: "proposal_label_reshape"
  top: "accuracy"
  accuracy_param {
    ignore_label: 255
  }
}

layer {
  name: "silence"
  type: "Silence"
  bottom: 'proposal'
  # bottom: 'affine_param'
  # bottom: 'lstm_other'
}
